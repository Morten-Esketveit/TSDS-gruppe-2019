{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import copy\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset for prediction\n",
    "Each observation/row is a connection (edge in the network). \n",
    "We want the following **route-specific** information: \n",
    "* Number of flights (\"count\") **done**\n",
    "* Distance (average distance?) **done**\n",
    "* Tid (average time?)  **done** \n",
    "\n",
    "\n",
    "We want the following **airport-specific** information: \n",
    "* Degree **done** \n",
    "* Clustering coefficient **done**\n",
    "* Betweenness centrality **done** \n",
    "* State? (administrative border?) **excluded**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data \n",
    "Data comes from http://stat-computing.org/dataexpo/2009/. \n",
    "Flight data relates to the year 2007 (see file StatComp_MER) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "Flights = pd.read_pickle(\"Flights.pkl\")\n",
    "#Airports = pd.read_pickle(\"airports.pkl\")\n",
    "\n",
    "# Select variables from which to create network. Must contain two columns of nodes, since \n",
    "# nx.from_pandas_edgelist() views each row as an edge. Can also contains attributes, e.g. Distance. \n",
    "FlightsNx = Flights[[\"Origin\",\"Dest\",\"Distance\"]]\n",
    "\n",
    "# Take counts (i.e. how many origin to destination flights in the dataset)\n",
    "counts = pd.DataFrame(Flights.groupby([\"Origin\",\"Dest\"])[\"Year\"].count())\n",
    "counts.columns = [\"count\"]\n",
    "FlightsNx = FlightsNx.merge(counts, how = 'left', on = [\"Origin\",\"Dest\"])\n",
    "\n",
    "# Drop duplicates \n",
    "FlightsNx = FlightsNx.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create average time for each route\n",
    "TimeMeans = pd.DataFrame(Flights.groupby([\"Origin\",\"Dest\"])[\"ActualElapsedTime\"].mean())\n",
    "# Merge to FlightsNx\n",
    "FlightsNx = FlightsNx.merge(TimeMeans, how = \"left\", on = [\"Origin\", \"Dest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create number of distinct companies on each route \n",
    "companies = pd.DataFrame(Flights.groupby([\"Origin\",\"Dest\"])[\"UniqueCarrier\"].nunique())\n",
    "companies.columns = [\"companies\"]\n",
    "FlightsNx = FlightsNx.merge(companies, how = \"left\", on = [\"Origin\", \"Dest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of take-offs from origin: \n",
    "orig_takeoff = pd.DataFrame(FlightsNx.groupby([\"Origin\"])[\"count\"].sum())\n",
    "orig_takeoff.columns = [\"origin_takeoff\"]\n",
    "# Merge to network dataset: \n",
    "FlightsNx = FlightsNx.merge(orig_takeoff, how = \"left\", on = \"Origin\")\n",
    "\n",
    "# Count number of take-offs from dest\n",
    "dest_takeoff = pd.DataFrame(FlightsNx.groupby([\"Origin\"])[\"count\"].sum())\n",
    "dest_takeoff.columns = [\"dest_takeoff\"]\n",
    "FlightsNx = FlightsNx.merge(dest_takeoff, how = \"left\", left_on = \"Dest\", right_on = \"Origin\")\n",
    "\n",
    "# Count number of landings at destination\n",
    "dest_lands = pd.DataFrame(FlightsNx.groupby([\"Dest\"])[\"count\"].sum())\n",
    "dest_lands.columns = [\"dest_landing\"]\n",
    "FlightsNx = FlightsNx.merge(dest_lands, how = \"left\", on = \"Dest\")\n",
    "\n",
    "orig_lands = pd.DataFrame(FlightsNx.groupby([\"Dest\"])[\"count\"].sum())\n",
    "orig_lands.columns = [\"orig_landing\"]\n",
    "FlightsNx = FlightsNx.merge(orig_lands, how = \"left\", left_on = \"Origin\", right_on = \"Dest\")\n",
    "\n",
    "# Construct totals (flights)\n",
    "FlightsNx[\"Origin_flights\"] = FlightsNx[\"origin_takeoff\"]+FlightsNx[\"orig_landing\"]\n",
    "FlightsNx[\"Destination_flights\"] = FlightsNx[\"dest_takeoff\"]+FlightsNx[\"dest_landing\"]\n",
    "\n",
    "# Drop auxiliary vars\n",
    "FlightsNx.drop([\"origin_takeoff\",\"dest_takeoff\",\"dest_landing\",\"orig_landing\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Network = nx.from_pandas_edgelist(FlightsNx, source = \"Origin\", target = \"Dest\", edge_attr = True)\n",
    "# docs: https://networkx.github.io/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.degree_centrality.html#networkx.algorithms.centrality.degree_centrality \n",
    "# Find degree: \n",
    "degree_dict = nx.algorithms.centrality.degree_centrality(Network) \n",
    "degree_values = list(degree_dict.values())\n",
    "# Create dataframe\n",
    "degrees = pd.DataFrame(degree_values)\n",
    "degrees.columns = [\"degree\"]\n",
    "degrees[\"degree_unnormalized\"] = degrees[\"degree\"]*(len(Network.nodes)-1)\n",
    "degrees[\"airport\"] = degree_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add degree to FlightsNx data\n",
    "FlightsNx = FlightsNx.merge(degrees, how = \"left\", left_on = \"Origin\", right_on = \"airport\")\n",
    "FlightsNx = FlightsNx.drop(\"airport\", axis = 1)\n",
    "FlightsNx = FlightsNx.rename(columns = {\"degree\": \"origin_degree\", \"degree_unnormalized\": \"origin_degree_unn\"})\n",
    "\n",
    "FlightsNx = FlightsNx.merge(degrees, how = \"left\", left_on = \"Dest\", right_on = \"airport\")\n",
    "FlightsNx = FlightsNx.drop(\"airport\", axis = 1)\n",
    "FlightsNx = FlightsNx.rename(columns = {\"degree\": \"dest_degree\", \"degree_unnormalized\": \"dest_degree_unn\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Betweenness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "btwn_dict = nx.betweenness_centrality(Network)\n",
    "btwns = pd.DataFrame(list(btwn_dict.values()))\n",
    "btwns.columns = [\"betweenness\"]\n",
    "btwns[\"airport\"] = btwn_dict.keys()\n",
    "\n",
    "FlightsNx = FlightsNx.merge(btwns, how = \"left\", left_on = \"Origin\", right_on = \"airport\")\n",
    "FlightsNx = FlightsNx.drop(\"airport\", axis = 1)\n",
    "FlightsNx = FlightsNx.rename(columns = ({\"betweenness\":\"origin_btwns\"}))\n",
    "\n",
    "FlightsNx = FlightsNx.merge(btwns, how = \"left\", left_on = \"Dest\", right_on = \"airport\")\n",
    "FlightsNx = FlightsNx.drop(\"airport\", axis = 1)\n",
    "FlightsNx = FlightsNx.rename(columns = ({\"betweenness\":\"dest_btwns\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FlightsNx.drop([\"origin_degree\",\"dest_degree\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FlightsNx = FlightsNx.rename(columns = ({\"ActualElapsedTime\":\"avg_time_mins\",\n",
    "                             \"origin_degree_unn\":\"origin_degree\",\n",
    "                             \"dest_degree_unn\":\"dest_degree\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering Coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = nx.algorithms.cluster.clustering(Network)\n",
    "clusters_df = pd.DataFrame(list(clusters.values()))\n",
    "clusters_df.columns = [\"clustering\"]\n",
    "clusters_df[\"airport\"] = clusters.keys()\n",
    "\n",
    "FlightsNx = FlightsNx.merge(clusters_df, how = \"left\", left_on = \"Origin\", right_on = \"airport\")\n",
    "FlightsNx = FlightsNx.drop(\"airport\", axis = 1)\n",
    "FlightsNx = FlightsNx.rename(columns = ({\"clustering\":\"origin_clustcoef\"}))\n",
    "\n",
    "FlightsNx = FlightsNx.merge(clusters_df, how = \"left\", left_on = \"Dest\", right_on = \"airport\")\n",
    "FlightsNx = FlightsNx.drop(\"airport\", axis = 1)\n",
    "FlightsNx = FlightsNx.rename(columns = ({\"clustering\":\"dest_clustcoef\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>count</th>\n",
       "      <th>avg_time_mins</th>\n",
       "      <th>companies</th>\n",
       "      <th>Origin_flights</th>\n",
       "      <th>Destination_flights</th>\n",
       "      <th>origin_degree</th>\n",
       "      <th>dest_degree</th>\n",
       "      <th>origin_btwns</th>\n",
       "      <th>dest_btwns</th>\n",
       "      <th>origin_clustcoef</th>\n",
       "      <th>dest_clustcoef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMF</td>\n",
       "      <td>ONT</td>\n",
       "      <td>389</td>\n",
       "      <td>4093</td>\n",
       "      <td>71.234185</td>\n",
       "      <td>1</td>\n",
       "      <td>116158</td>\n",
       "      <td>83287.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.011491</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.486258</td>\n",
       "      <td>0.597436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMF</td>\n",
       "      <td>PDX</td>\n",
       "      <td>479</td>\n",
       "      <td>2721</td>\n",
       "      <td>83.317127</td>\n",
       "      <td>2</td>\n",
       "      <td>116158</td>\n",
       "      <td>117237.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.011491</td>\n",
       "      <td>0.003647</td>\n",
       "      <td>0.486258</td>\n",
       "      <td>0.591362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMF</td>\n",
       "      <td>PHX</td>\n",
       "      <td>647</td>\n",
       "      <td>4184</td>\n",
       "      <td>106.243087</td>\n",
       "      <td>3</td>\n",
       "      <td>116158</td>\n",
       "      <td>422170.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.011491</td>\n",
       "      <td>0.028447</td>\n",
       "      <td>0.486258</td>\n",
       "      <td>0.375392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMF</td>\n",
       "      <td>SAN</td>\n",
       "      <td>480</td>\n",
       "      <td>4895</td>\n",
       "      <td>81.599257</td>\n",
       "      <td>2</td>\n",
       "      <td>116158</td>\n",
       "      <td>194618.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.011491</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>0.486258</td>\n",
       "      <td>0.593614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMF</td>\n",
       "      <td>SEA</td>\n",
       "      <td>605</td>\n",
       "      <td>3519</td>\n",
       "      <td>106.077896</td>\n",
       "      <td>2</td>\n",
       "      <td>116158</td>\n",
       "      <td>218274.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.011491</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>0.486258</td>\n",
       "      <td>0.475410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Origin Dest  Distance  count  avg_time_mins  companies  Origin_flights  \\\n",
       "0    SMF  ONT       389   4093      71.234185          1          116158   \n",
       "1    SMF  PDX       479   2721      83.317127          2          116158   \n",
       "2    SMF  PHX       647   4184     106.243087          3          116158   \n",
       "3    SMF  SAN       480   4895      81.599257          2          116158   \n",
       "4    SMF  SEA       605   3519     106.077896          2          116158   \n",
       "\n",
       "   Destination_flights  origin_degree  dest_degree  origin_btwns  dest_btwns  \\\n",
       "0              83287.0           44.0         40.0      0.011491    0.003241   \n",
       "1             117237.0           44.0         43.0      0.011491    0.003647   \n",
       "2             422170.0           44.0         88.0      0.011491    0.028447   \n",
       "3             194618.0           44.0         53.0      0.011491    0.002061   \n",
       "4             218274.0           44.0         61.0      0.011491    0.044200   \n",
       "\n",
       "   origin_clustcoef  dest_clustcoef  \n",
       "0          0.486258        0.597436  \n",
       "1          0.486258        0.591362  \n",
       "2          0.486258        0.375392  \n",
       "3          0.486258        0.593614  \n",
       "4          0.486258        0.475410  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FlightsNx.to_pickle(\"FlightsML.pkl\")\n",
    "FlightsNx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Homophily? \n",
    "## \" Does these features contribute? i.e. raise predictive performance?\"\n",
    "## Number of different companies?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
